%! TEX root = ../msc.tex
\chapter{Introduction}
\label{ch:basics}
\epigraph{I am fascinated by numbers}{
\citeauthor{baron-cohenAutismSpectrumQuotientAQ2001}}
%\cite{baron-cohenAutismSpectrumQuotientAQ2001}}

Was hier useful werden kann:

Nielsen: \cite{nielsenQuantumComputationQuantum2010}

Stabilizer Formalism, Gottesman PhD thesis: \cite{gottesmanStabilizerCodesQuantum1997}

Algorithm for simulating stabilizer circuits:
\cite{aaronsonImprovedSimulationStabilizer2004}

stabilizer lecture notes: \cite{arabLectureNotesQuantum2024}

Entanglement with Stabilizers: \cite{fattalEntanglementStabilizerFormalism2004}

Aaronson's quantum information theory I and II lecture notes:
\cite{aaronsonIntroductionQuantumInformation,aaronsonIntroductionQuantumInformationa}.
This one's a huge find!

another huge find! gottesman lecture notes on quantum error correction:
\cite{gottesmanSurvivingQuantumComputer2024}

Zee Group Theory in a nutshell: \cite{zeeGroupTheoryNutshell2016}

This chapter serves to familiarize the reader with the core concepts relevant
to this thesis. We will first introduce the stabilizer formalism, as it will
later enable us to perform efficient numerical experiments on a classical
computer. We then provide a general introduction to the field of entanglement
transitions and go over some important examples. 
\section{The Stabilizer Formalism}\label{sec:stab-basics}
In this section we review the most important concepts of the stabilizer
formalism. 

Section adapted from \cite{nielsenQuantumComputationQuantum2010} and
\cite{gottesmanStabilizerCodesQuantum1997}
\subsection{Basic notions of group theory}
Group theory is one of the most important algebraic notions in theoretical
phyiscs. From classifying crystalline structures (cite Ashcroft Mermin),
(gauge) symmetries in the standard model (cite some yang mills stuff), to the
classification of (topological) phase transitions (cite nicolai phd?), group
theory perpetually permeates theoretical physiscs.

The stabilizer formalism makes no exception. It is a clever application of
group theory, allowing for a more compact representation of quantum states,
compared to the state vector. We therefore introduce necessary prerequesites of
group theory needed for the stabilizer formalism and its role in this thesis,
starting with the notion of a group.

A group $G$ is a collection of some particulars $g$ that can be composed
according to some convention. To be called a group, the set of entities
$\{g\}$ and the operation\footnote{In the discussion on groups and group
  theory, the words composition, group operation, and multiplication are used
interchangibly} with which we compose them, need to obey a certain
ruleset. This ruleset, called the group axioms, reads as follows.

\begin{defn}[Group]\label{defn:group}
  A group $G$ is a non-empty set equipped with a binary operation (here denoted
  with $\cdot$) that satisfy
  \begin{description}
    \item[Associativity] The group operation is associative, i.e.
      $$\forall a,b,c \in G:\ (a\cdot b) \cdot c = a \cdot
      (b \cdot c)$$
    \item[Identity element] The group contains an identity element, which does
      nothing with respect to composition, i.e.
      $$\exists I\in G \ \forall g \in G : I\cdot g = g \cdot I = g$$
    \item[Inverse element] Each group element has a unique element associated
      to it that when composed with it gives the identity. In other words,
      $$\forall g \in G \ \exists g^{-1} \in G : g g^{-1} = g^{-1} g = I $$
  \end{description}
\end{defn}

Note that we do not require the group elements to commute with respect to
multiplication. Groups that satisfy commutativity for all their elements are
called \emph{abelian} groups.

Numerous different mathematical objects and concepts can fall under the
umbrella of group theory.\footnote{One can even describe the Rubik's Cube
puzzle in the language of group theory} Although we will discuss specific
groups in greater detail later, we do not want to fail to mention some other
important groups appearing all across physics. There are the rotation groups
$SO(n)$ and unitary groups $U(n)$ (both in $n$ dimensions), the permutation
group of $n$ elements $S_n$ and the group of square roots of $1$ under
multiplication, $\mathbb{Z}_2 = \{1, -1\}$.  The first two are examples of
continuous groups, while the others are discrete, meaning that they have a
finite number of elements. The number of elements in a discrete group $G$ is
called the \emph{order} of a group, which we write as $\mathrm{ord}(G)$.

For larger finite groups, it can become cumbersome to keep track of all the
elements and their relation to each other. Luckily, there is a way we can
condense all the information to construct the whole group in its
\emph{presentation}, also known as its \emph{generating set}. The elements of
such a generating set are referred to as \emph{generators}.
\begin{defn}[Generating set and generators]\label{defn:generators}
  Let $G$ be a finite group and $S$ a subset of $G$. $S$ is called a generating
  set of $G$ if all elements in $G$ can be obtained from (possibly repeated)
  multiplication of elements in the generating set. Generating sets are denoted
  by angled braces, such that we write
  \begin{align}
    S = \langle g_1, \ldots, g_n \rangle, \quad g_1,\ldots, g_n \in G
  .\end{align}
  The $g_i$ are called \emph{generators} of $G$. The trivial group $\left(
  \{I\}, \cdot \right)$ is generated by the empty set.
\end{defn}

While there are also generators of continuous groups, they take on a
fundamentally different form compared to the discrete counterpart. As an
example of a discrete generating set, consider the group of fourth roots of $1$
with multiplication, $Z_4 = \left( \{\pm 1,\pm i\}, \cdot \right)$. It is easy
to verify that the subset $S = \{i\}$ of the group uniquely reproduces all of
the elements in $Z_4$, by taking powers of $i$.

In the process of constructing a generating set we are generally faced with two
restrictions. The first is the fact that the entire group needs to emerge from
the multiplications of generators. We cannot simply choose arbitrary group
elements. $S=\{-1\}\subset Z_4$ would be a perfectly fine set of generators for
$\mathbb{Z}_2$, but not $Z_4$. Next, we ideally want to have the least number
of generators possible to build up the rest of the group. This restriction is
one we impose on ourselves rather than one imposed on us by necessity. Choosing
$S=\{-1, i, -i\}$ as generators also recovers $Z_4$, however, we have already
seen that $g=-1$ and $g=-i$ are redundant in this context.
\Cref{thm:maxsize-generators} gives a lower bound on the number of generators
needed to generate finite groups.

\begin{thm}\label{thm:maxsize-generators} 
  The minimum size of a generating set for a finite group $G$ of generators is
  at most $\log_2(\mathrm{ord}(G))$
\end{thm}

%\begin{proof} We prove the theorem by induction over the size of 
%
%  As base case we have Let $G$ be a finite group with minimal generating set
%  $S_n = \langle g_1, \ldots, g_n\rangle.$
%\end{proof}

With \cref{thm:maxsize-generators} we have that for $Z_4$, choosing a
generating set with $3$ elements should be cause for concern, since we would
need $2$ at most. However, we also saw that $Z_4$ is special in that way, since
we only needed one generator. A way of quantifying this quality is the
\emph{rank} of a group.  It is defined as the size of the smallest generating
set of $G$ and is denoted by $\abs{G}$. Thus, for the example of $Z_4$ we have
$\abs{Z_4}=1$. 
\newpage
When discussing subsets of groups, one naturally arising concept is the notion
of subgroups. Suppose we take some set of elements $\{g\}$ forming a group $G$
under multiplication and take a subset $\{h\}$ thereof. If the subset also
forms a group $H$, we call it a subgroup of $G$ and write $H \leq G$.

\begin{defn}[Subgroup]\label{defn:subgroup}
  A subgroup $H$ of $G$, written as $H \leq G$, is a non-empty subset $H$ of $G$, which forms
  a group under the same group operation as $G$. 
\end{defn}

Going back to some of the previous examples, we can consider $SO(2)$, rotations
along the unit circle, as rotations on the equator of a unit sphere. We can
consequently take $SO(2)$ as a subgroup of the rotation group of the unit
sphere $SO(3)$. The group of permutations of $m \leq n$ elements is just the
group of permutations of $n$ elements, where $n-m$ elements are left invariant,
and as such $S_m \leq S_n$. Note that for any group $G$ we have $G \leq G$ and
$(\{I\}, \cdot) \leq G$, where $\left( \{I\}, \cdot \right)$ is the trivial
group containing only the identity. These two special cases are referred to as
\emph{trivial subgroups}. Subgroups that are not trivial are called
\emph{proper subgroups} denoted by $H<G$.

Before introducing another important family of subgroups, we define a special
kind of operation known as \emph{conjugation}. If $h,g\in G$, the conjugate of
$h$ with respect to $g$ is $g^{-1} h g$.\footnote{This operation is
colloquially referred to as \enquote{sandwiching} $h$ with $g$.}
We can not only perform this operation on individual group elements, but also
subgroups of $G$. 
Consider the proper subgroup $H<G$ with elements $\{h_i\}$. 
%Another important family of subgroups are \emph{invariant} subgroups. Let $H$
%be a group of elements $\{h\}$ with $H<G$.
If we take any element $g \in G
\setminus H$, we can arrive at another subgroup of $G$ by conjugating all
elements of the
subgroup $H$ with $g$, written as
\begin{align}
  g^{-1}Hg = \{ g^{-1} h g \ \mid \ h \in H \}
.\end{align}
In general, the two subgroups $H$ and $g^{-1}Hg$ need not be the same. However,
if there are some $g$, which leave $H$ invariant under conjugation, we say that
these $g$ \emph{normalize} $H$. A collection of these normalizing elements can
be compiled together to form yet another subgroup of $G$, called the
normalizer.
\begin{defn}[Normalizer]\label{defn:normalizer}
  Let $G$ be a group and $H < G$ a proper subgroup of $G$. The normalizer of
  $H$ in $G$ is the subgroup of $G$ that leaves $H$ invariant under
  conjugation, i.e.
  \begin{align}
    N_G(H) = \{ g \in G \mid \ g^{-1} H g = H \}
  .\end{align}
\end{defn}
In the special case of every element of $G$ normalizing $H$, that is $N_G(H) =
G$, $H$ is called an \emph{invariant subgroup} of $G$. In the next section we
will introduce an important example of a finite group and its normalizer. 
%However,
%if, for an arbitrary choice of $g$, they are the same, then $H$ is called
%\emph{invariant subgroup} of $G$.
%\begin{defn}[Invariant subgroup]\label{defn:normal-subgroup}
%  Let $G, H$ be groups with $H\lt G$. We call $H$ an invariant (or normal)
%  subgroup of $G$ if
%  \begin{align}
%    \forall g \in G, \forall h \in H: \ g^{-1} h g \in H
%  .\end{align}
%\end{defn}
\subsection{The Pauli group and Clifford gates}

Consider the Pauli matrices with the identity,
\begin{align}
  \sigma_0 = I = \mqty(\pmat{0}),\quad \sigma_x = \mqty(\pmat{1}), \quad \sigma_y =
  \mqty(\pmat{2}), \quad \text{and}\quad \sigma_z = \mqty(\pmat{3})
.\end{align}
These well-known matrices are both hermitian and unitary, and consequently
square to the identity. For the latter three of them one can show that they
satisfy the following commutation and anticommutation relations,
\begin{equation}\label{eq:pauli-comm}
 \begin{split}
  [\sigma_j, \sigma_k] &= 2\mathrm{i}\epsilon_{jkl}\sigma_l \\
  \{\sigma_j, \sigma_k\} &= 2I \delta_{jk}\quad \text{and} \\
  \sigma_j \sigma_k &= \frac{1}{2}\left([\sigma_j,\sigma_k] +
  \{\sigma_j,\sigma_k\}  \right) = \delta_{jk} I + \mathrm{i} \epsilon_{jkl}
  \sigma_l
,\end{split} 
\end{equation}
with the Levi-Civita tensor $\epsilon_{jkl}$ (where Einstein summation
convention is implied) and the Kronecker delta $\delta_{jk}$. Furthermore, the latter
three are traceless and have eigenvalues of $\pm 1$.
To ease up on the
indices, especially once tensor products of Pauli matrices come into play, one also writes the Pauli matrix with the corresponding capital
letter, $\sigma_x = X, \ldots$. These matrices also form a basis for hermitian
$2\times 2$ matrices. Recall that physical observables are represented by
hermitian matrices. We can therefore consider the Pauli matrices as a basis for
physical observables on qubits. 

While they also play
an important role in representation theory, especially of Lie and Clifford
algebras, they themselves also form a group known as the Pauli group
$\mathcal{P}$. The single-qubit Pauli group is defined as the Pauli matrices
with phases $\pm 1$ and $\pm i$,
\begin{align}
  \mathcal{P} = \{\pm I, \pm i I, \pm X, \pm i X, \pm Y, \pm i Y, \pm Z, \pm i
  Z \}
.\end{align}
This definition can also be generalized to $n$ qubits.
\begin{defn}[Pauli group]\label{defn:pauligroup}
  The Pauli group $\mathcal{P}_n$ is composed of tensor products of $I,\ X,\
  Y,$ and $Z$ on $n$ qubits with an overall phase of $\pm 1$ and $\pm i$.
\end{defn}
From \cref{eq:pauli-comm} it follows that $\mathcal{P}_n$ is not Abelian.
The commutation relations can be extended for the tensor products of Paulis,
but there are some cases that then commute non-trivially. For instance,
$X_1\otimes X_2 \equiv X_1X_2$ commutes with $Z_1\otimes Z_2\equiv Z_1Z_2$, even though the individual
Pauli matrices in the tensor products do not commute. These commutation
relations can be compacted into a general statement on tensor products of Pauli
operators. Two $n$-qubit Pauli operators commute non-trivially if there are an
even number of anticommuting pairs in the tensor product structure. This
excludes the identity, of course, since everything commutes trivially with the
identity. The task of finding the commutation relation between two operators
then becomes a counting task.

Another group worth considering is the Clifford group, $\mathsf{C}_n$, which is
often defined as the subgroup of unitary matrices with dimension $2^n$ that
normalize (cf. \cref{defn:normalizer}) the $n$-qubit Pauli group,
$$\mathsf{C}_n = \{ u \in U\left(2^n\right) \mid u^\dagger \mathcal{P}_n u
= \mathcal{P}_n \}.$$
Instead of being a finite group, since it includes all matrices of the form
$u= e^{i\varphi} I$ with some phase $\varphi \in \mathbb{R}$, the Clifford
group defined in this way is continuous. By defining it in terms of a finite
subgroup of the above definition, the physical significance of the Clifford
group also becomes apparent.

\begin{defn}[Clifford gates]\label{defn:cliffords}
  The Clifford group is the group generated by the Hadamard, Phase and CNOT
  gates. These are called the Clifford gates. 
\end{defn}

The Clifford gates form an important subset of gates in quantum computing and
especially quantum error correction (\textcolor{orange}{hier ein paar citations
vielleicht}). However, it should be noted that they do not form a universal set
of quantum gates. While the gates in the Clifford group can create entangled
states with the Hadamard and CNOT gates, one needs an additional gate to
achieve universal quantum computation.
\subsection{The stabilizer group}

So far we have only examined groups in isolation. Among other things, we have
shown that the group generated by the Clifford gates normalizes the Pauli
group.  However, the major role group theory plays in physics can best be
demonstrated if one considers the action of group elements on other
mathematical objects outside of the group. These could be, for example,
Lagrangians, or more relevant for us, state vectors. If we consider the
two-qubit state vector $\ket{+} = \left( \ket{0} + \ket{1} \right) / \sqrt{2}$.
As an eigenstate of the Pauli operator $X$, we can tell that this state is
resistant to bitflips.  The group-theoretic way to put this is to say that
$\ket{+}$ is $\mathbb{Z}_2$-symmetric. This notion of symmetry is where group
theory finds most of its utility in physics.  As an additional example,
consider the 2-qubit Bell state

\begin{align}
  \ket{\phi} = \frac{\ket{00} + \ket{11}}{\sqrt{2}} 
.\end{align}

Note that the unitary operations $X_1 X_2$ and $Z_1 Z_2$ both have $\ket{\phi}$
as eigenstate with eigenvalue $+1$. Since $$X_1X_2Z_1Z_2\ket{\phi} = \ket{\phi} =
Z_1Z_2X_1X_2\ket{\phi}$$ we can also see how these two operators commute with each
other. The operators $X_1X_2$ and $Z_1Z_2$ are then said to \emph{stabilize} the
state $\ket{\phi}$. It is easy to convince oneself that these operations
stabilizing the state $\ket{\phi}$ should form a group. Doing nothing, i.e. the
identity $I$, clearly stabilizes the state, and since the Pauli matrices square
to the identity, each element of this stabilizer group is its own inverse (we
omit verifying associativity, as this is inherited from $\mathcal{P}_n$). The
matrices $X_1X_2$ and $Z_1Z_2$ therefore generate a symmetry group of
$\ket{\phi}$, since their product is clearly also a symmetry transformation on
$\ket{\phi}$. We therefore introduce the final group theoretic notion, the
symmetry group.

\begin{defn}[Symmetry group]\label{defn:fixpointgroup}
  Let $G$ be a group acting on a set $M$. Let $a\in M$. We then call the
  subgroup
  \[ H = \left\{ h \in G \mid ha = a \right\} \leq G \]
  \emph{symmetry group} or \emph{fixpoint group} of $a$.
\end{defn}

In our example, we have the group of $2$-qubit Pauli matrices, $\mathcal{P}_2$,
acting on the $2$-qubit Hilbert space $H^{\otimes 2}$.
%The symmetry group of
%$\ket{\phi} \in H^{\otimes 2}$ is the subgroup of Pauli matrices that have the
%state as eigenvector with eigenvalue $+1$. 
In general, we say that a unitary $U$ stabilizes a pure state $\ket{\psi}$ if
$U\ket{\psi} = \ket{\psi}$. In other words, the stabilizer group of a pure
state
$\ket{\psi}$ is the set of all unitaries that have $\ket{\psi}$ as eigenvector
with eigenvalue $+1$. For all further considerations we restrict the unitaries
to Pauli operators. Thus, the formal definition of an $n$-qubit stabilizer
group can be stated as follows.

\begin{defn}[Stabilizer group]\label{defn:stabilizergroup}
  Let $H^{\otimes n}$ denote the $n$-qubit Hilbert space. Given a subset $V_S
  \subseteq H^{\otimes n}$, the stabilizer is defined as
  \begin{align}
    \mathcal{S}_V = \{ g \in \mathcal{P}_n \mid g \ket{\phi} = \ket{\phi} \
    \forall \ket{\phi} \in V \} \leq \mathcal{P}_n
  .\end{align}
\end{defn}

It would, in principle, be possible to define stabilizer groups of all
unitaries instead of the Pauli group. We will later see, however, that this
restriction leads to an important result, namely \cref{thm:gottesman-knill}.

We note that global phase matters here. The operators with prefactor, such as
$-I$ are not in the stabilizer. Furthermore, we have that the stabilizer is an
Abelian subgroup of $\mathcal{P}_n$, which can be shown by generalizing the
example above. We can show the necessity of this condition in the following.
Suppose $\ket{\phi}\in V_S$ is non-zero, and $M$ and $N$ are in $\mathcal{S}$. Since $M$
and $N$ are tensor products of Pauli matrices, they either commute or
anticommute. If they anticommute we have
\begin{align}
  \ket{\phi} = MN\ket{\phi} = -NM\ket{\phi} = -\ket{\phi}
,\end{align}
leading to a contradiction, since we had $\ket{\phi}$ being non-zero. (By the
same argument we can rule out $-I$ to be in the stabilizer.)

At this point, we need to be careful not to put the cart before the horse. The stabilizer
group is not the stabilizer of $V_S$ as such. If that were the case, then $V_S
= \{ \ket{00}, \ket{11}\}$ would be stabilized by $X_1X_2$. Rather, $V_S$ is
the intersection of subspaces spanned by the eigenvalue $+1$ eigenspaces of 
$\mathcal{S}$. What this means is that when working with the stabilizer formalism, we would
much rather first write out an Abelian subgroup of the Pauli group (without
$-I$) and then
deduce the subspace stabilized by this subgroup. 

\begin{defn}[Stabilized state space]\label{defn:stab-statespace}
  Let $\mathcal{S} \leq \mathcal{P}_n$ be Abelian with $-I \not\in
  \mathcal{S}$. The space of states stabilized by $\mathcal{S}$ is
  \begin{align}
    V_S = \{ \ket{\phi} \mid g\ket{\phi} = \ket{\phi} \ \forall g \in
    \mathcal{S} \}
  .\end{align}
\end{defn}

So far, it is not entirely obvious how keeping track of operators growing
exponentially in size is a worthwhile method of representing quantum states or
subspaces of a larger state space.
However, we can simplify the problem drastically by realizing two facts.

The first is summarized in \cref{defn:generators,thm:maxsize-generators}.
Recall that we can equivalently write a finite group as a collection of at most
$\log(\mathrm{ord}(G))$ generators. The Bell state example from above has a
full stabilizer group of $\mathcal{S} = \{I, X_1X_2, -Y_1Y_2, Z_1Z_2\}$. With
\cref{eq:pauli-comm} we can infer that $X_1X_2\cdot Z_1Z_2 = -Y_1Y_2$, and
since all of them square to the identity, an equivalent form of the stabilizer
group is given by the generating set $G = \langle X_1X_2, Z_1Z_2\rangle$.
Note that while the generating set is explicitly not the entire group, the
distinction between the two is kept rather loosely. Oftentimes we will write
that some stabilizer group $\mathcal{S}$ is equal to its generating set. This is mostly a matter of
convenience and reabability. If context does not explicitly demand it, we write
the generating set and the group interchangibly.

The second fact is a more subtle one. It uses the commutation relations
laid out in \cref{eq:pauli-comm}. If we briefly neglect the phases again, or keep
track of them separately, we can write $Y=XZ$. As such, we can encode the
entire stabilizer group in a bit matrix, where $I \equiv 00$, $Z \equiv 01$, $X
\equiv 10,$ and $Y \equiv 11$. The bit matrix of the Bell state is
\begin{align}
  \mathcal{S} \equiv \mqty[1 & 1 & 0 & 0 \\ 0 & 0 & 1 & 1]
.\end{align}
This check matrix has a multitude of different use cases, one of them being the
focus of the entirety of \cref{ch:mixed}.
Another one is that if the rows of the
check matrix are linearly independent (mod 2), we have a minimal generating
set. The generators of such a minimal generating set are then called
independent. 

\subsubsection{Stabilizer density matrix}
Before we go on to discuss the dynamics in the stabilizer formalism, i.e.
stabilizer circuits, we define the density matrix for stabilizers. We know that
a stabilizer group $\mathcal{S}$ consists of Pauli operators, which share eigenstates. 
Thus, the density matrix of a pure state $\rho = \dyad{\phi}$ is a
projector onto all $+1$ eigenstates of the Pauli operators in the stabilizer.
This can be constructed by multiplying the projectors onto $+1$ eigenstates of
the generating set. This follows from $\mathbb{P}^2 = \mathbb{P}$ and the fact
that the generating set recovers the whole group with multiplication. Since we
can write projectors of Pauli operators $g$ as $\mathbb{P} = \frac{1}{2}(I+g)$,
we can write
\begin{align}
  \rho = \frac{1}{2^n} \prod_{i=1}^n (I + g_i)
\end{align}
for the density matrix of a pure state.

A mixed state in the stabilizer formalism can be described by removing
generators from the generating set. 
\begin{defn}[Stabilizer density matrix]\label{defn:stab-dmat}
  Let $\mathcal{S}$ be an $n$-qubit stabilizer group with generating set
  $\langle g_1, \ldots, g_l \rangle$ with $0 \leq l \leq n$. The density matrix
  corresponding to this stabilizer group is given by
  \begin{align}
    \rho = \frac{1}{2^n} \prod_{i=1}^l (I + g_i)
  \end{align}
  or alternatively as
  \begin{align}
    \rho = \frac{1}{2^n} \sum_{s \in \mathcal{S}} s
  .\end{align}
\end{defn}

\subsubsection{Entropy of entanglement}

With the notion of a density matrix defined in the stabilizer formalism, we can
ask the question about entropic quantities. Since we introduce methods to
compute other entropic and information-theoretic quantities in
\cref{sec:rel-ent-stab}, we will here only define the entropy of entanglement.
Its definition can be stated as follows.
\begin{defn}[Entropy of entanglement]\label{defn:entent}
  Let $\ket{\phi}\in H^{\otimes N}$ be a bipartite pure state with subsystems
  $A$ and $B$. The entropy of entanglement of $\ket{\phi}$ then reads
  \begin{align}
    %&S_E : H^{\otimes N} \to [0, N/2]\nonumber\\
    S_\mathrm{E}\left(\ket{\phi}\right) = - \Tr[\rho_B \log \rho_B],
  \end{align}
  where $\rho_B = \Tr_A[\dyad{\phi}]$ is the reduced density matrix of subsystem
  $B$. Conventionally, one uses the logarithm of base 2.
\end{defn}

In bipartite states this quantity measures how entangled one subsystem is with
the other. That is, it gives a numerical value to the non-local correlations between
subsystems. If we split our stabilizer group into local subgroups of $A$ and
$B$, $\mathcal{S}_A$ and $\mathcal{S}_B$, we have the possibility of another
subgroup remaining, namely $\mathcal{S}_{AB}$ accounting for correlations.
$\mathcal{S}_{A(B)}$ are subgroups containing only operators acting on $A (B)$.
If we split our stabilizer group in this way, we find that there is a nice
closed-form expression for the entanglement entropy
\cite{fattalEntanglementStabilizerFormalism2004}.

\begin{thm}[Entropy of entanglement -- stabilizer]\label{thm:entent}
  The entropy of entanglement of a bipartite pure state $\ket{\phi}_{AB}$ with
  partitions $A$ and $B$ is given
  by
  \begin{align}\label{eq:entent}
    S_E(\ket{\phi}) = \frac{1}{2}\abs{\mathcal{S}_{AB}}
  .\end{align}
\end{thm}
For
the 2-qubit Bell state we once again have $\mathcal{S} = \langle XX,
ZZ\rangle$. Notice that $\mathcal{S}_A = \mathcal{S}_B = \{I\}$ and $\mathcal{S}_{AB} =
\mathcal{S}$. 
The entropy of entanglement between $A$ and $B$ should be $1$
since there is only 1 independent entangled pair. We could additionally compute
the reduced density matrices and the matrix logarithm instead, arriving at the
same result.

With \cref{eq:entent} we find that this result is also obtained by counting the
generators in $\mathcal{S}_{AB}$, which is $2$, then dividing by $2$, which
gives the correct result of $1$. 
\subsection{Stabilizer circuits}

Finally, we discuss the dynamics of stabilizer states in quantum circuits. This
is where we can see the main advantages of the stabilizer formalism, as it will
ultimately lead to the efficient simulation of a wide class of quantum circuits
with classical computers. 
As introductory note we define a stabilizer circuit to be a quantum
circuit using only Clifford gates and measurement gates of Pauli operators. Let
us therefore begin by discussing unitary gates.

\subsubsection{Unitary gates}
Suppose we apply a unitary $U$ to a vector space $V_S$ stabilized by
$\mathcal{S}$. For any $\ket{\phi} \in V_S$ and any $g \in \mathcal{S}$ we have
\begin{align}
  U\ket{\phi} = U g \ket{\phi} = U g \underbrace{U^\dagger U}_{I} \ket{\phi}
.\end{align}
We thus have that the state $U\ket{\phi}$ is stabilized by the operator
$UgU^\dagger$. Since our choices of $\ket{\phi}$ and $g$ were arbitrary in
$V_S$ and $\mathcal{S}$, respectively, we have that the transformed vector
space is stabilized by the conjugated stabilizer group
\begin{align}
  USU^\dagger = \{ UgU^\dagger \mid g \in \mathcal{S}\}
.\end{align}
Since we restricted ourselves to unitary gates in the Clifford group, which
normalizes the Pauli group, we still exclusively have Pauli operators in
$USU^\dagger$. Our task then becomes to track the effects of Clifford group
elements on a subset of Pauli operators. In particular, we conjugate the
generators in the generating set with the unitary operation corresponding to
the applied gate. Let us therefore consider the
conjugation of the Pauli matrices with the unitary Clifford gates.
For the Hadamard gate $H = \frac{X+Z}{\sqrt{2}}$ we have
\begin{align}
  HXH^\dagger = Z, \quad HYH^\dagger = -Y, \quad HZH^\dagger = X
\end{align}
For the CNOT gate $U$ with qubit 1 as control and qubit 2 as target we have
\begin{alignat}{2}
  UX_1U^\dagger &= X_1X_2, \quad &&UX_2U^\dagger = X_2 \label{eq:cnot-x}\\
  UZ_1U^\dagger &= Z_1, \quad &&UZ_2U^\dagger = Z_1Z_2
,\end{alignat}
where for all other two qubit Pauli operators we can use the above relations
and \cref{eq:pauli-comm} to
deduce their conjugation relations. Furthermore, we already know an efficient method
of tracking generating sets through $X$ and $Z$ alone.
Lastly, we want to consider the action of the phase gate on the Pauli
operators,
\begin{align}
  SXS^\dagger = Y \quad SZS^\dagger = Z
.\end{align}

Note that the Clifford gates being the normalizer of the Pauli group means that
we will inevitably lose gates, which would realize universal quantum computing.
Notable examples of gates not included in the gate set generated by the
Clifford group are the $T$ gate, also known as $\pi /8$ gate, and the Toffoli
gates.

\subsubsection{Measurements}

We now know the mechanisms behind unitary gates in the stabilizer formalism.
However, we can also include measurement gates in quantum circuits. It turns
out that measurements can also be described in a simple way in the stabilizer
formalism. Since physical observables are represented by hermitian operators,
we can assume that the measurement operator is a product of Pauli matrices $M
\in\mathcal{P}_n$. Suppose we measure $M$ in a system in a state $\ket{\phi}$
with stabilizer group $\mathcal{S} = \langle g_1, \ldots, g_n\rangle$. Two
questions naturally arise: what is the measurement result, and how does the
stabilizer group transform under this measurement?

To answer both of these, we first need to realize the two distinct
possibilities:
\begin{enumerate}
  \item $M$ commutes with all the generators of the stabilizer group.
  \item $M$ anti-commutes with at least one of the generators. By restructuring
    the generating set, we can ensure that there is at most one generator
    anticommuting with $M$. We thus assume without loss of generality that $M$
    anticommutes with $g_1$.
\end{enumerate}

For the first case, we have that either $M$ or $-M$ is itself an element of the
stabilizer group, since for arbirtary generators $g_j$
\begin{align}
  g_j M \ket{\phi} = M g_j \ket{\phi} = M\ket{\phi}
.\end{align}
As this holds for any $g_j$, we have that $M\ket{\phi}=\pm \ket{\phi}$, where
either $\pm M$ is in the stabilizer group. Assuming w.l.o.g. that
$M\in\mathcal{S}$, we have that the measurement of $M$ yields the result $+1$
with probability one, i.e. deterministically. Since the stabilizer group
already contained $M$, it does not change. 

In the second case, we have that the measurement operator anticommutes with
$g_1$. Note that the projectors for the measurement outcomes are $\mathbb{P} =
\frac{1}{2}\left( I\pm M \right)$. Therefore, the probabilities for the
respective outcomes are given by
\begin{align}
  P(\pm 1) = \Tr[\frac{1}{2}\left( I\pm M \right) \dyad{\phi}]
.\end{align}
With $g_1 \ket{\phi} = \ket{\phi}$ and $\{g_1, M\} =0$ we have
\begin{align}
  P(+1) &= \Tr[\frac{I+M}{2} g_1 \dyad{\phi}] \nonumber\\
        &= \Tr[g_1 \frac{I-M}{2} \dyad{\phi}] \nonumber\\
        &= \Tr[\frac{I-M}{2} \dyad{\phi} g_1] \nonumber\\
        &= \Tr[\frac{I-M}{2} \dyad{\phi}] = P(-1)
.\end{align}
Since we can only measure $+1$ or $-1$ and the probabilities for either are
equal, we can deduce that $P(\pm 1) = 1 / 2$. After the measurement, the
generating set gets affected such that it is now
$\rangle \pm M, g_2, \ldots, g_n\rangle$ depending on the measurement outcome.

\subsubsection{Stabilizer circuits and error correction}

No discussion of the stabilizer formalism would be complete without as much as
a mention of its applications in quantum error correction. To this end,
consider the following quantum circuit shown in
\cref{fig:error-detection-circuit}. A variation of this circuit will play
an important role in our discussion of the projective transverse-field Ising
model in \cref{sec:intro-ptim}.

\begin{figure}[H]
  \centering
  \input{fig/tikz/entangling-gate.tex}
  \caption{Circuit showing the error detection and correction capabilities
    within the stabilizer formalism.  First, a Bell cluster is created by the
    application of the Hadamard and two CNOT gates.  Afterwards, an error
    occurs in the form of an $X$ measurement, which we can attempt to detect
    via stabilizer measurements.}
  \label{fig:error-detection-circuit}
\end{figure}

Initially, we have the state $\ket{000}$, which is stabilized by $\mathcal{S} =
\langle Z_1, Z_2, Z_3 \rangle$. At the first vertical line our generators were
conjugated with $H_1$, such that we now have $\mathcal{S} = \langle X_1, Z_2,
Z_3 \rangle$. The corrresponding state stabilized by $\mathcal{S}$ is
$\ket{+}\otimes\ket{00}=\frac{\ket{0}+\ket{1}}{\sqrt{2}} \otimes \ket{00}$.
After the first CNOT, we have $\mathcal{S} = \langle X_1X_2,Z_1Z_2,Z_3\rangle$
according to the transformation rules given in \cref{eq:cnot-x}. Before the measurement on qubit 1, we
apply another CNOT gate, thus creating a 3-qubit Bell cluster
$(\ket{000}+\ket{111}) / \sqrt{2}$ with stabilizer group $\mathcal{S}= \langle
X_1X_2X_3,Z_1Z_2,Z_2Z_3\rangle$. 

Then, an error occurs in the form of an $X$ measurement on qubit 3. The
stabilizer generators are now $\langle X_1X_2, Z_1Z_2, X_3\rangle$, which we
are, in principle, unaware of. However,
since we are performing syndrome measurements afterwards in the form of $ZZ$
measurements, we can detect, and subsequently correct the error. In our
example, a measurement of $Z_1Z_2$ would be a measurement of a stabilizer
generator, and would thus yield $+1$. Next, we measure $Z_2Z_3$. According to
the previously introduced rules, the outcome is $\pm 1$ with probability
$\frac{1}{2}$ and the stabilizer generators afterwards are $\mathcal{S} =
\langle X_1X_2X_3, Z_1Z_2, \pm Z_2Z_3\rangle$. In the case where the outcome is
$+1$, we effectively corrected the error already, since we recovered the
previous stabilizers. In the converse case, we at least detected the syndrome
of the error: bit flip on qubit $3$ must have occurred! We can then correct the
error appropriately and flip it back by means of applying a Pauli-$X$.
%We then measure the first qubit in the
%computational basis. We have that $\{Z_1,X_1\} = 0$, and thus a random outcome
%to the measurement. However, after the measurement we are guaranteed to have
%stabilizers in the form of $\mathcal{S} = \langle \pm Z_1, Z_1Z_2,
%Z_2Z_3\rangle$.

\subsubsection{Simulation of stabilizer circuits}
Simulating stabilizer circuits can thus be done by keeping track of all the
generators and updating them accordingly. As we have seen in above example, we
were not required to perform exponentially hard calculations to get to the
final state of the circuit. This fact can be used to formulate the following
theorem \cite{gottesmanHeisenbergRepresentationQuantum1998}.
%Currently verbatim from \cite{nielsenQuantumComputationQuantum2010}! Beware!
%Actual source is \emph{inside}
%\cite{gottesmanHeisenbergRepresentationQuantum1998}, basically stating "trust
%me bro" (one of the most important theorems of quantum computation is cited as
%private communication in its original source\ldots)
\begin{thm}[Gottesman-Knill theorem]\label{thm:gottesman-knill}
  Suppose a quantum computation is performed which involves only the following
  elements: state preparations in the computational basis, Clifford gates, and
  measurements of observables in the Pauli group (which includes measurement in
  the computational basis as a special case), together with the possibility of
  classical control conditioned on the outcome of such measurements. Such
  computation may be efficiently simulated on a classical computer.
\end{thm}

We will forego a detailed discussion of the simulation of stabilizer circuits
on classical computers, as well as the proof to \cref{thm:gottesman-knill}
until \cref{ch:mixed}. For now we remind ourselves that the Clifford gate set
does not constitute a universal set of quantum gates. Thus, classical computers
\emph{cannot} suffice to efficiently simulate quantum computers

\section{Entanglement Transitions}\label{sec:ent-trans}

Random assortment of MIPT Paper (incomplete):

\begin{itemize}
  \item Fisher paper, das ich mir als allererstes mal durchgelesen hab
    (\citetitle{liMeasurementdrivenEntanglementTransition2019}):
    \cite{liMeasurementdrivenEntanglementTransition2019}
  \item MIPT general, war in \cref{ch:lxe}, aber leider keine ahnung mehr
    warum\ldots (\citetitle{baoTheoryPhaseTransition2020}) \cite{baoTheoryPhaseTransition2020}
  \item \citetitle{baoSymmetryEnrichedPhases2021}
    \cite{baoSymmetryEnrichedPhases2021}
  \item Why not: Measurement induced synchronization von Finn
    (\citetitle{schmolkeMeasurementinducedQuantumSynchronization2023}):
    \cite{schmolkeMeasurementinducedQuantumSynchronization2023}
  \item 2017 WR for quantum state tomography (10 qubits):
    (\citetitle{song10QubitEntanglementParallel2017})
    \cite{song10QubitEntanglementParallel2017}
  \item LXE: Definition: \cite{liCrossEntropyBenchmark2023}; PTIM:
    \cite{tikhanovskayaUniversalityCrossEntropy2023}
  \item Garratt/Altman Paper:
    (\citetitle{garrattProbingPostmeasurementEntanglement2023}) \cite{garrattProbingPostmeasurementEntanglement2023}
  \item self-cite for clout:
    (\citetitle{schmolkeBoostingInformationTransfer2024})
    \cite{schmolkeBoostingInformationTransfer2024}
\end{itemize}

more curated MIPT collection:
\begin{itemize}
  \item Skinner Lecture notes on MIPT
    \cite{skinnerLectureNotesIntroduction2023}
  \item ist zwei mal in meiner zotero library, vielleicht mal auschecken: 
    \cite{hokeMeasurementinducedEntanglementTeleportation2023}
  \item Titel klingt vielversprechend: \cite{baoTheoryPhaseTransition2020}
  \item Ideen von Finn: \cite{joshiObservingQuantumMpemba2024,aresEntanglementAsymmetryProbe2023}
  \item PRX von skinner 1: \cite{skinnerMeasurementInducedPhaseTransitions2019}
    chronologisch das erste
  \item PRX von skinner 2: \cite{nahumMeasurementEntanglementPhase2021}
  \item PRX von skinner 3:
    \cite{nahumEntanglementDynamicsDiffusionannihilation2020}
    Das hat Felix immer auf gemacht um mir das mit den Majoranas zu zeigen
  \item eins noch for good measure:
    \cite{yoshidaDecodingEntanglementStructure2021}
\end{itemize}
%\begin{figure}[H]
%  \centering
%  \input{fig/tikz/intro-hybridcircuit.tex}
%  \caption{Hybrid Circuit Tikz picture??}
%  \label{fig:hybrid-circuit}
%\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics{Untitled.png}
  \caption{Hybrid Circuit Tikz picture??}
  \label{fig:hybrid-circuit}
\end{figure}

\subsection{Phenomenology}

\section{The Projective Transverse-Field Ising Model}\label{sec:intro-ptim}
\begin{itemize}
  \item PTIM paper: \citetitle{langEntanglementTransitionProjective2020}
    \cite{langEntanglementTransitionProjective2020}
  \item Felix decoder paper: \citetitle{roserDecodingProjectiveTransverse2023}
    \cite{roserDecodingProjectiveTransverse2023}
  \item Colored Cluster Model!
  \item There should be a Skinner paper, but I don't have it in my zotero
    library (yet)
  \item Its \cite{nahumEntanglementDynamicsDiffusionannihilation2020}
\end{itemize}

\begin{figure}[t]
  \centering
  \input{fig/tikz/intro-ptim.tex}
  \caption{Tikz sketch of PTIM setup with $\approx 10$ qubits}
  \label{fig:ptim-circuit}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics{Untitled.png}
  \caption{plot of entanglement entropy (and mutual information??) as a
  function of $p$. multiple system sizes, possibly rather large ($\approx 512$
qubits?, maybe $N=\{128,256,512\}$ just for the fun of it). Would need to
include mutual information in the source code.}
  \label{fig:phase-transition}
\end{figure}

\section{Sampling Problem}\label{sec:sampling}
The metaphysics of this endeavour can
be condensed in the following way; we (a) know from experiments how quantum
systems behave under certain conditions, and (b) predict through theoretical
calculations what these systems might do in another experimental setting. In
the latter case however, there is an uncanny regime of utility, where we either
(a) cannot precisely pass predictions or (b) cannot perform the experiment on
the grounds of hardware limitations\footnote{The Higgs particle was predicted
40 years before it was discovered \textcolor{red}{citation}} or (c) try to
predict the behavior of quantities not directly measurable. In the case of
quantum computation, and especially in the field of entanglement transitions,
we face these bottlenecks in increasing severity. To make do with them, we
employ classical computer simulations. That is, we perform numerical
experiments. While traditional experiments still serve as the sole proprietor of claim to
ontology, numerical experiments can play a supporting role, 

In the year of our
lord 2024, we phyisicists are thankfully able to perform experiments at home
with cleverly assembled silicon.  That is, nowadays we make do with these
bottlenecks by performing numerical experiments. This is not to discredit the
utility of experiments as such, on the contrary! 

\subsection{Fisher: Linear Cross Entropy}
\cite{liCrossEntropyBenchmark2023}

\subsection{Altman: Upper Bound}
\cite{garrattProbingPostmeasurementEntanglement2024}
